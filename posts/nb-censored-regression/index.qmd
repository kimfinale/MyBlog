---
title: "Regression with censorted data: POLYMOD data"
author: "Jong-Hoon Kim"
date: "2023-10-12"
categories: [R, regression, contact, censor]
image: "unnamed-chunk-5-1.png"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```

### Data prep

This post describes the process to analyze the POLYMOD data set, which can be downloaded from [Social Contact Data](http://www.socialcontactdata.org/).

```{r}
library(data.table)
library(dplyr)
d <- fread("C:/Users/jonghoon.kim/Documents/myblog/posts/nb-censored-regression/2008_Mossong_POLYMOD_participant_common.csv")
d2 <- fread("C:/Users/jonghoon.kim/Documents/myblog/posts/nb-censored-regression/2008_Mossong_POLYMOD_contact_common.csv")
# count the number of contacts for each participant using part_id variable
d2 |> 
  dplyr::group_by(part_id) |>
  summarize(contacts = n()) -> d_contacts
  
d <- dplyr::left_join(d, d_contacts, by="part_id")
# add household information
d3 <- fread("C:/Users/jonghoon.kim/Documents/myblog/posts/nb-stan/2008_Mossong_POLYMOD_hh_common.csv")
d <- dplyr::left_join(d, d3, by="hh_id")
# add day of week information
d4 <- fread("C:/Users/jonghoon.kim/Documents/myblog/posts/nb-stan/2008_Mossong_POLYMOD_sday.csv")
dat <- dplyr::left_join(d, d4, by="part_id")
```

### Age group

Categorize the age group into different 10 age groups: 0-4, 5-9, 10-14, 15-19,
20 to 70 by 10 years and 70 and above
```{r}
d <- dat
d$age_grp <- 99
for (i in 1:nrow(d)) {
  if(!is.na(d$part_age[i])){
    if(d$part_age[i] < 5){
      d$age_grp[i] <- 0
    }
    else if (d$part_age[i] >= 5 && d$part_age[i] < 20){
      for(j in 1:3){
        if(d$part_age[i] >= 5*j && d$part_age[i] < (5*j+5)){
          d$age_grp[i] <- j
        }
      }
    }
    else if (d$part_age[i] >= 20 && d$part_age[i] < 70){
      for (k in 1:5){
        if (d$part_age[i] >= (10+10*k) && d$part_age[i] < (20+10*k)){
          d$age_grp[i] <- k+3
        }
      }
    } 
    else {
      d$age_grp[i] <- 9
    }
  } 
}

d$hh_size_grp <- ifelse(d$hh_size > 4, 5, ifelse(!is.na(d$hh_size), d$hh_size, NA))

# d$gender_grp <- ifelse(d$part_gender == "F", "F", 
#                        ifelse(d$part_gender == "M", "M", NA))

dat <- d

dat$age_grp <- as.factor(dat$age_grp)
dat$hh_size_grp <- as.factor(dat$hh_size_grp)
dat$gender <- as.factor(dat$part_gender)
dat$dayofweek <- as.factor(dat$dayofweek)
```

### Weighting

```{r}
# hh <- fread("posts/nb-stan/2008_Mossong_POLYMOD_hh_common.csv")
# d3 <- left_join(d2, hh, by="hh_id") 
# # match by country, household size, age group
# library(readxl)

# Determining a row and a column is simply based on the way it is imported  rio::import_list("posts/nb-stan/sampling_weight.xlsx")
d <- dat
d$age_row <- NA
for (i in 1:nrow(d)) {
  ag <- d$part_age[i]
  if(!is.na(ag)){
    for (j in 1:14) {
      if (ag >= (j-1)*5 & ag < (j-1)*5+5) {
        d$age_row[i] <- j
        break
      }
      else if (ag >= 70) {
        d$age_row[i] <- 15
        break
      }
      else{}
    }
  }
}

d$hh_col <- NA
for (i in 1:nrow(d)) {
  hs <- d$hh_size[i]
  if(!is.na(hs)){
    for (j in 1:4) {
      if (hs == j) {
        d$hh_col[i] <- j
        break
      }
      else if (hs > 4) {
        d$hh_col[i] <- 5
      }
      else{}
    }
  }
}

d$wt <- NA
wlist <- rio::import_list("C:/Users/jonghoon.kim/Documents/myblog/posts/nb-stan/sampling_weight.xlsx")
cnames <- names(wlist)
for (i in 1:length(cnames)) {
  wtable <- wlist[[i]]
  w1 <- wtable[wtable$`Household size` == "Ratio C/S",] # sampling weight
  W <- w1[!is.na(w1$`Household size`),] # remove the first row
  # View(W)
  for (j in 1:nrow(d)){
    if(d$country[j] == cnames[i]) {
      d$wt[j] <- W[d$age_row[j], d$hh_col[j]+2]
    }
  }
}
# grep("-", as.character(d$wt), value = T)
# hist(as.numeric(d$wt))
dat <- d
dat$wt <- as.numeric(dat$wt)
```

### data for fitting only complete cases

```{r}
dat_ <- dat
dat <- dat[complete.cases(dat),]
```

### NegBin regression: no censoring and no weighting

```{r}
library(MASS)

m1 <- glm.nb(contacts ~ age_grp, data = dat)
summary(m1)
exp(m1$coefficients)

m2 <- glm.nb(contacts ~ age_grp + gender, data = dat)
summary(m2)
exp(m2$coefficients)

m3 <- glm.nb(contacts ~ age_grp + gender + hh_size_grp , data = dat)
summary(m2)
exp(m2$coefficients)

m4 <- glm.nb(contacts ~ age_grp + gender + hh_size_grp + country, data = dat)
# summary(m4)
exp(m4$coefficients)

m5 <- glm.nb(contacts ~ age_grp + gender + hh_size_grp + country + dayofweek, data = dat)
# summary(m4)
exp(m5$coefficients)
```

### Take censoring into account

```{r}
m <- m5
X = model.matrix(m)
# ini = c(coef(m1), log_theta = log(summary(m1)$theta))
init = c(coef(m), size=summary(m)$theta)

negll_censor <- function(par, y, X, ul=400) {
  # parameters
  size = par[length(par)] 
  beta = par[-length(par)]
  # create indicator depending on chosen limit
  indicator = y < ul
  # linear predictor
  mu = exp(X %*% beta)
  # log likelihood
  ll = sum(indicator * dnbinom(y, mu=mu, size=size, log=T) + 
             (1-indicator) * log(1-pnbinom(ul, mu=mu, size=size, lower=0)), na.rm=T)
  return(-ll)
}

fit <- optim(par=init, 
            negll_censor,
            y = dat$contacts,
            X = X,
            ul = 100,
            method = "Nelder-Mead",
            control = list(maxit=1e3, reltol=1e-10))

exp(coef(m))
exp(fit$par)

fit1 <- optim(par=init, 
            negll_censor,
            y = dat$contacts,
            X = X,
            ul = 29,
            method = "Nelder-Mead",
            control = list(maxit=1e3, reltol=1e-10))
fit1$par
exp(coef(m))
```

Censoring & Weighting

```{r}
m <- m2
X = model.matrix(m)
# ini = c(coef(m1), log_theta = log(summary(m1)$theta))
init = c(coef(m), size=summary(m)$theta)

negll_censor_weight <- function(par, y, X, wt, ul=400) {
  # parameters
  size = par[length(par)] 
  beta = par[-length(par)]
  # create indicator depending on chosen limit
  indicator = y < ul
  # linear predictor
  mu = exp(X %*% beta)
  # log likelihood
  ll = sum(wt*(indicator * dnbinom(y, mu=mu, size=size, log=T)
  + (1-indicator) * log(1-pnbinom(ul, mu=mu, size=size, lower=0))), na.rm=T)
  
  return(-ll)
}

fit <- optim(par=init, 
            negll_censor_weight,
            y = dat$contacts,
            X = X,
            wt = 1,
            ul = 100,
            method = "Nelder-Mead",
            control = list(maxit=1e3, reltol=1e-10))
exp(coef(m))
exp(fit$par)

fit1 <- optim(par=init, 
            negll_censor_weight,
            y = dat$contacts,
            X = X,
            wt = dat$wt,
            ul = 100,
            method = "Nelder-Mead",
            control = list(maxit=1e3, reltol=1e-10))

exp(fit1$par)

fit2 <- optim(par=init, 
            negll_censor_weight,
            y = dat$contacts,
            X = X,
            wt = dat$wt,
            ul = 29,
            method = "Nelder-Mead",
            control = list(maxit=1e3, reltol=1e-10))
exp(fit2$par)
```