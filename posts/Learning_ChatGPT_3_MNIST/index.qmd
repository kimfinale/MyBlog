---
title: "Learning ChatGPT 3: MNIST"
author: "Jong-Hoon Kim"
date: "2024-06-16"
categories: [Neural network, MNIST, CNN]
image: "mnist_five.png"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```


The following contents were adapted based on  [this](https://jtr13.github.io/cc21fall2/tutorial-on-r-torch-package.html) and 
[this](https://blog.naver.com/flynt1/222419808861) pages.

```{r}
library(torch)
library(torchvision)
library(caret)
library(tidyverse)
library(reshape2) # melt function
```


### Data

Data were downloaded using the following command: `torchvision::mnist_dataset(".", download=T)`.
```{r}
train = readRDS("training.rds")
test = readRDS("test.rds")
# train[[1]] indicate numeric values for the image and train[[2]] indicate the correct number
dim(train[[1]])
dim(test[[1]])
n_train <- 60000
n_test <- 10000
```


Plot the image

```{r}
train[[2]][40000]

image <- train[[1]][40000, 1:28, 1:28]
image_df <- melt(image)
ggplot(image_df, aes(x=Var2, y=-Var1, fill=value))+ # reorient the image
  geom_tile(show.legend = FALSE) + 
  xlab("") + ylab("") +
  scale_fill_gradient(low="white", high="black")+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      legend.position="none",
      panel.background=element_blank(),
      panel.border=element_blank(),
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank())

train[[2]][40000]
```

Convert data to tensor type  
```{r}
device = "gpu"

x_train =
  train[[1]] %>% 
  torch_tensor(device = device, dtype = torch_float32()) %>% 
  torch_reshape(list(n_train, 1, 28, 28)) 

x_train = x_train$divide(255) # normalize

y_train =
  train[[2]] %>% 
  factor(levels = c(0:9)) %>% 
  torch_tensor(device = device, dtype = torch_int64())

x_test =
  test[[1]] %>% 
  torch_tensor(device = device, dtype = torch_float32()) %>% 
  torch_reshape(list(n_test, 1, 28, 28))
x_test = x_test$divide(255) 

y_test =
  test[[2]] %>%
  factor(levels = c(0:9)) %>% 
  torch_tensor(device = device, dtype = torch_int64())
```


dataloader

```{r}
batch.size <- 200

train_loader =
  dataloader(
    tensor_dataset(x_train, y_train),
    batch_size = batch.size,
    shuffle = T)

test_loader =
  dataloader(
    tensor_dataset(x_test, y_test),
    batch_size = batch.size)
```

Network 

```{r}
network = nn_module(
  classname = "cnn.model",
  initialize= function(){
    self$cv1= nn_conv2d(in_channels = 1,
                        out_channels =32,
                        kernel_size = 5,
                        padding = 2)
    self$cv2= nn_conv2d(in_channels = 32,
                        out_channels = 64,
                        kernel_size = 5,
                        padding = 2)
    self$pool= nn_max_pool2d(kernel_size = 2,
                             stride = 2)
    self$fc1= nn_linear(64*7*7, 100)
    self$fc2= nn_linear(100, 10)
  },
  forward= function(M){
    M %>%               # [batch.size, 1, 28, 28]
      self$cv1() %>%    # [batch.size, 32, 28, 28]
      nnf_relu() %>% 
      self$pool() %>%   # [batch.size, 32, 14, 14]
      self$cv2() %>%    # [batch.size, 64, 14, 14]
      nnf_relu() %>% 
      self$pool() %>%   # [batch.size, 64, 7, 7]
      torch_flatten(start_dim = 2) %>% 
      self$fc1() %>% 
      nnf_relu() %>% 
      self$fc2() %>% 
      nnf_softmax(2)
  }
)
```

Set the seed, loss function, and the optimizer 
```{r}
set.seed(1234)
model = network()
model$to(device = device)

loss.func = nn_cross_entropy_loss()
optimizer = optim_adam(model$parameters, lr=0.001)
```

Train the network
```{r}
epoch = 10
train_loss = vector()
test_loss = vector()

for (i in 1:epoch) {
  for (b in enumerate(train_loader)){
    optimizer$zero_grad()
    output = model$forward(b[[1]])
    loss = loss.func(output, b[[2]])
    loss$backward()
    optimizer$step()
    train_loss = c(train_loss, loss$item())
  }

  for (b in enumerate(test_loader)) {
    model$eval()
    output = model$forward(b[[1]])
    loss = loss.func(output, b[[2]])
    test_loss = c(test_loss, loss$item())
    model$train()
  }
}
```

Plot the loss

```{r}
# train_loss <- readRDS("train_loss.rds")
# test_loss <- readRDS("test_loss.rds")

tibble(i = seq(1, length(train_loss)), train = train_loss) %>% 
  ggplot()+
  geom_line(aes(i, train), color="gray", size=0.1)+
  theme_bw()

tibble(i = seq(1, length(test_loss)), test = test_loss) %>% 
  ggplot()+
  geom_line(aes(i, test), color="blue", size=0.1)+
  theme_bw()
```

Accuracy
```{r}
pred = vector()
for (b in enumerate(test_loader)) {
    output = 
      model$forward(b[[1]]) %>% 
      torch_max(2) %>% 
      .[[2]]
    pred = c(pred, output$to(device = device) %>% as_array())
}

tibble(
  label = y_test$to(device = device) %>% as_array() %>% as.factor(),
  pred = pred %>% as.factor()) %>% 
  with(., caret::confusionMatrix(pred, label))

```


