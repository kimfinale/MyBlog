{
  "hash": "7fe29fc0bff008273445c880d74ec043",
  "result": {
    "markdown": "---\ntitle: \"Bayesian workflow: fake social contact data example\"\nauthor: \"Jong-Hoon Kim\"\ndate: \"2024-07-21\"\ncategories: [Bayesian workflow, negative binomial, social contact]\nimage: \"sample_figure.png\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Bayesian workflow\n\nThis post is an my attempt to follow along a [Bayesian Workflow](https://arxiv.org/abs/2011.01808) by Gelman _et al_ and create examples for better understanding. While my ultimate goal is to study infectious disease transmission using a dynamic model following a Bayesian workflow, I use a simpler statistical model to practice in this post. I also consulted a [blog post](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#31_Example_Workflow_Executions) by Michael Betancourt to create this post. \n \nRegarding the definition of Bayesian workflow, [Gelman _et al_.](https://arxiv.org/abs/2011.01808) writes:\n\n> \"... Bayesian inference is just the formulation and computation of conditional probability or probability densities, $p(\\theta|y) \\propto p(\\theta) p(y|\\theta)$. Bayesian workflow includes the three steps of model building, inference, and model checking/improvement, along with the comparison of different models, not just for the purpose of model choice or model averaging but more importantly to better understand these models ... \"  \n\n## Model building\n\n### Conceptual analysis\n\nLet's suppose that we measured how the number of contact a person makes varies.[A prior study](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0050074) and other numerous studies showed that contact frequencies differ by age. And a significant fraction of contacts occur with household members and as such the contact frequencies will likely vary by household size. We sampled a group of people and followed them for some time (e.g., 1 week) and measured the number of contacts that a typical person makes in a day. We also collected variables such as age, sex, and household size.\n\nThere are three conceptual modelling approaches: descriptive, predictive and explanatory approaches as per [the study by Shmueli](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf). This study is best described as a descriptive study and does not directly aim at obtaining optimal predictive performance, but at capturing the data structure parsimoniously. For a descriptive model, interpretability, transportability and general usability are important criteria as described in the [article](ttps://diagnprognres.biomedcentral.com/articles/10.1186/s41512-020-00074-3). \n\nAssuming that the number of contacts per day per person, $y_i$, follows a negative binomial distribution, we can mathematically express our concepts in the following equations:\n\n$$\ny_i \\sim \\text{NB}(y_i|\\mu_i,\\phi)=\\frac{\\Gamma (y_i + \\theta)}{\\Gamma (\\theta) y_i !}) \\left(\\frac{\\mu_i}{\\mu_i+\\phi} \\right)^y \\left(\\frac{\\phi}{\\mu_i+\\phi} \\right)^\\phi\n$${#eq-nb}\n\n$$\\text{log}(\\mu_i)= \\alpha + \\beta_{\\text{age}_i}  + \\beta_{\\text{sex}_i} +\\beta_{\\text{hhsize}_i}$${#eq-mu}\n\n$\\mu_i$ and $\\phi$ represent the mean number of contacts per day for a person $i$ and the shape parameter of the negative binomial distribution, respectively. $\\Gamma (\\cdot)$ denotes a [gamma function](https://en.wikipedia.org/wiki/Gamma_function).\n\n### Implemetation\n\nLoad packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(posterior)\noptions(pillar.neg = FALSE, pillar.subtle=FALSE, pillar.sigfig=2)\nlibrary(brms)\nlibrary(tidyverse)\nlibrary(bayesplot)\ntheme_set(bayesplot::theme_default(base_family = \"sans\"))\nset1 <- RColorBrewer::brewer.pal(7, \"Set1\")\n```\n:::\n\n\nGenerate the fake data\n\nWe take the fake-data simulation approach, which can help us understand our\ndata model and priors, what can be learned from an experiment, and the validity of the applied inference methods. Parameters of interest are the ratios of number of contacts per day (i.e., rate ratios or relative risks) by age, sex, and household size. Plugging @eq-mu into @eq-nb becomes our generative model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameter values to be estimated\nintercept_true <- 3 # base number of contacts\nrr_age_true <- c(1.5, 0.6) # relative number of contacts by age (age0 = 1)\nrr_hhsize_true <- c(2, 2.6) # relative number of contacts by household size  (hhsize0 =1)  \nrr_sex_true <- c(1.2) # males have more frequent contacts, which is not modeled in model 1\nshape_true <- 5 # shape parameter for the negative binomial distribution\n\nset.seed(42)\n# 9 categories with >100 observations on average\nd <- data.frame(age = sample(1:3, 1000, replace=T),\n                hhsize = sample(1:3, 1000, replace=T), \n                sex = sample(1:2, 1000, replace=T))\nd$b_age <- \n  ifelse(d$age == 1, 1, \n         ifelse(d$age == 2, rr_age_true[1], rr_age_true[2])) # relative risk by age\nd$b_hhsize <- \n  ifelse(d$hhsize == 1, 1, \n         ifelse(d$hhsize == 2, rr_hhsize_true[1], rr_hhsize_true[2])) # relative risk by household size\nd$b_sex <- \n  ifelse(d$hhsize == 1, 1, rr_sex_true) # relative risk by\n\n# mean as a function of age and hhsize\na <- intercept_true \nlog_mu <- log(a) + log(d$b_age) + log(d$b_hhsize) + log(d$b_sex)\nd$mu <- exp(log_mu)\nd$age <- as.factor(d$age)\nd$hhsize <- as.factor(d$hhsize)\nd$sex <- as.factor(d$sex)\nd$contacts <- rnbinom(nrow(d), mu=d$mu, size=shape_true) # size, aka, shape, dispersion\n```\n:::\n\n\nHistogram, mean, and variance of the data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nd |> \n  ggplot(aes(x=contacts))+\n  geom_histogram(binwidth=1, fill=set1[2])+\n  theme_light()+\n  labs(x=\"Number of contacts per day per person\", y=\"Frequency\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmean(d$contacts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.85\n```\n:::\n\n```{.r .cell-code}\nvar(d$contacts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31.42492\n```\n:::\n:::\n\nThe number of contacts is count data and the variance-to-mean ratio is around 5. Thefore, the choice of negative binomial distribution looks reasonable.\n\n### Model 1: age and household size \n\nFor this model, we assume that the dependent variable is mostly influenced by age and household size and do not include sex variable in the model.  \n\nWe use the `brms` package to implement the Bayesian regression model. We first set the priors for the intercept, `a_*`, the age and household size, \n`b_*`, and the shape parameter of the negative binomial distribution, `shp_*`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prior distributions\n# intercept, modeled as normal\na_mean <- 0\na_scale <- 1.5 # exp(2*a_scale) will likely cover plausible values \n# beta for the age and the household, modeled as normal\nb_mean <- 0\nb_scale <- 1.5\n# shape parameter of the negbin distr, modeled as inverse gamma\nshp_alpha <- 0.8 # 0.4 (brms default) causes divergent transitions,\nshp_beta <- 0.3\n\nmy_priors <- \n  c(prior_string(paste0(\"normal(\", a_mean, \",\", a_scale,\")\"), \n                 class = \"Intercept\"),\n    prior_string(paste0(\"normal(\", b_mean, \",\", b_scale,\")\"),\n                 class = \"b\"),\n    prior_string(paste0(\"inv_gamma(\", shp_alpha, \",\", shp_beta,\")\"), \n                 class=\"shape\"))\n```\n:::\n\n\n### Prior predictive check\n\nWe use `sample_prior = \"only\"` argument to get the prior predictive distribution. \n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred <- brm(contacts ~ 1 + age + hhsize,\n                 data = d,\n                 family = negbinomial(),\n                 prior = my_priors,\n                 iter = 1e4, sample_prior = \"only\", cores = 4)\n\nsaveRDS(prior_pred, \"prior_pred.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred <- readRDS(\"prior_pred.rds\")\npriorpc <- pp_check(prior_pred, type=\"bars\", ndraws = 200)\n\npriorpc$data |> \n  ggplot(aes(x=x))+\n  geom_col(aes(y=y_obs, fill=\"Data\"))+\n  geom_point(aes(y=m, color=\"Prior\"))+\n  geom_linerange(aes(ymax=h, ymin=l, color=\"Prior\"))+\n  scale_x_continuous(limits=c(-1,30))+\n  labs(x=\"Number of contacts per day per person\", y=\"Frequency\")+\n  scale_color_manual(\"\", values=c(\"Prior\" = set1[3]))+\n  scale_fill_manual(\"\", values=c(\"Data\" = set1[2]))+\n  theme_bw()+\n  theme(legend.position=c(0.8,0.8))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n### Fit the model\n\n[Gelman _et al_.](https://arxiv.org/abs/2011.01808)\nwrites: \n\n> \" ... The first step in validating computation is to check that the model actually finishes the fitting process in an acceptable time frame and the convergence diagnostics are reasonable. In the context of HMC, this is primarily the absence of divergent transitions, $\\hat{R}$ diagnostic near 1, and sufficient effective sample sizes for the central tendency, the tail quantiles, and the energy (Vehtari et al., 2020). ...\" \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- brm(contacts ~ 1 + age + hhsize, \n           data = d, \n           family = negbinomial(),\n           prior = my_priors,\n           iter = 1e4, cores = 4)\nsaveRDS(fit1, \"fit1.rds\")\n```\n:::\n\n\n`brms` package reports all the relevant information to check the fitting.\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- readRDS(\"fit1.rds\")\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: contacts ~ 1 + age + hhsize \n   Data: d (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.13      0.05     1.04     1.22 1.00    17035    13697\nage2          0.40      0.04     0.32     0.49 1.00    20548    15508\nage3         -0.47      0.05    -0.57    -0.37 1.00    20229    15028\nhhsize2       0.78      0.05     0.68     0.88 1.00    17675    15906\nhhsize3       1.10      0.05     1.01     1.20 1.00    17685    16213\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     5.30      0.45     4.48     6.24 1.00    22342    14546\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n### Posterior predictive values along with prior predictive values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred <- readRDS(\"prior_pred.rds\")\npriorpc <- pp_check(prior_pred, type=\"bars\", ndraws = 200)\npostpc <- pp_check(fit1, type=\"bars\", ndraws = 200)\n\npostpc$data |> \n  ggplot(aes(x=x))+\n  geom_col(aes(y=y_obs, fill=\"Data\"))+\n  geom_point(data=priorpc$data, aes(y=m, color=\"Prior\"))+\n  geom_linerange(data=priorpc$data,aes(ymax=h, ymin=l, color=\"Prior\"))+\n  geom_point(aes(y=m, color=\"Posterior\"))+\n  geom_linerange(aes(ymax=h, ymin=l, color=\"Posterior\"))+\n  scale_x_continuous(limits=c(-1,30))+\n  labs(x=\"Number of contacts per day per person\", y= \"Frequency\")+\n  scale_color_manual(\"\", values=c(\"Prior\"=set1[3],\n                               \"Posterior\"=set1[4]))+\n  scale_fill_manual(\"\", values=c(\"Data\"=set1[2]))+\n  theme_bw()+\n  theme(legend.position=c(0.8,0.8))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Inference\n\nPrior and posterior distributions of parameters. \nTrace plots and histograms\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1, pars = \"^b_\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# plot(fit, pars = \".*age*.\")\n# plot(fit, pars = \".*hhsize*.\")\n```\n:::\n\n\nCorrelations\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit1, pars = \".*age*.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThere is a positive correlation between `b_age2` and `b_age3`. It appears that increase in one parameter creates a deviation from the specified distribution (negative binomial distribution) and the other parameter also increases for all predicted values conform to the specified distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit1, pars = \"^b_age*.|^In*.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nI also expected that the increase in those parameters (`b_age2` and `b_age3`) lead to the decrease in the `Intercept` to maintain the mean. This is, however, only clear when examining the association among `Intercept`, `b_hhsize2`, and `b_hhsize3`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit1, pars = \".*hh*.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\npairs(fit1, pars = \"^b_hh*.|^In*.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n\n$\\beta_{\\text{age}}$ parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_post <- as.data.frame(fit1)\nx <- seq(-2, 2, 0.01)\ndf <- data.frame(x=seq(-2, 2, 0.01))\ndf$prior_density <-  dnorm(df$x, b_mean, b_scale)\n\nplot(exp(x), dnorm(x, b_mean, b_scale), type=\"l\", ylim=c(0, 20), \n     xlab=\"Value\", ylab=\"Density\", main=expression(beta[age]))\nlines(density(exp(df_post$b_age2)), col=set1[2])\nlines(density(exp(df_post$b_age3)), col=set1[3])\nabline(v=rr_age_true, col=set1[1], lwd=1.2, lty=\"dotted\")\nlegend(\"topright\",\n       bty = \"n\",\n       lty=c(1,1,1,3),\n       col=c(1,set1[2],set1[3],set1[1]),\n       legend=c(\"Prior\",\"age2\",\"age3\",\"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ggplot2 way\n# ggplot()+\n#   geom_line(data=df, aes(x=exp(x), y=prior_density, color=\"Prior\"))+\n#   geom_density(data=df_post, aes(x=exp(b_age2), color=\"Posterior b_age2\"))+\n#   geom_density(data=df_post, aes(x=exp(b_age3), color=\"Posterior b_age3\"))+\n#   scale_color_manual(values=c(\"Prior\"=\"forestgreen\", \n#                               \"Posterior b_age2\"=\"firebrick\",\n#                               \"Posterior b_age3\"=\"steelblue\"))+\n#   labs(color=\"\", x=\"value\", y=\"density\")+\n#   theme(legend.position=\"bottom\")\n```\n:::\n\n\n$\\beta_{\\text{hhsize}}$ parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(exp(x), dnorm(x, b_mean, b_scale), type=\"l\", ylim=c(0,5), \n     xlab=\"Value\", ylab=\"Density\", main=expression(beta[hhsize]))\nlines(density(exp(df_post$b_hhsize2)), col=set1[2])\nlines(density(exp(df_post$b_hhsize3)), col=set1[2])\nabline(v=rr_hhsize_true, col=set1[1], lwd=1.2, lty=\"dotted\")\n\nlegend(\"topright\",\n       bty = \"n\",\n       lty=c(1,1,1,3),\n       col=c(1, set1[2], set1[3], set1[1]),\n       legend=c(\"Prior\", \"hhsize2\", \"hhsize3\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nIntercept\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-3,3,0.01)\nplot(exp(x), dnorm(x, a_mean, a_scale), type=\"l\", ylim=c(0,4), \n     xlab=\"Value\", ylab=\"Density\", main=\"Intercept\")\nlines(density(exp(df_post$b_Intercept)), col=set1[2])\nabline(v=intercept_true, col=set1[1], lwd=1.2, lty=\"dotted\")\nlegend(\"topright\",\n       bty = \"n\",\n       lty=c(1,1,3),\n       col=c(1,set1[2],set1[1]),\n       legend=c(\"Prior\", \"Posterior\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nShape parameter\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(extraDistr)\n\nx <- seq(0,10,0.01)\nplot(x, dinvgamma(x, shp_alpha, shp_beta), type=\"l\", \n     ylim=c(0,2), xlab=\"Value\", ylab=\"Density\", main=\"Shape\")\nlines(density(df_post$shape), col=set1[2])\nabline(v=shape_true, col=set1[1], lwd=1.2, lty=\"dotted\")\nlegend(\"topright\",\n       bty = \"n\",\n       lty=c(1,1,3),\n       col=c(1,set1[2],set1[1]),\n       legend=c(\"Prior\", \"Posterior\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## Model checking, improvement, and comparing multiple models\n\nGelman *et al*. writes: \n\n> \"...  The key aspect of Bayesian workflow, which takes it beyond Bayesian data analysis, is that we are fitting many models while working on a single problem. We are not talking here about model selection or model averaging but rather of the use of a series of fitted models to better understand each one. ...\"\n\n### Model evaluation\n\nWe use leave-one-out (LOO) cross validation as suggested in [Vehtari *et al.*](https://link.springer.com/article/10.1007/s11222-016-9696-4) and  [Gelman *et al.*](https://link.springer.com/article/10.1007/s11222-013-9416-2).\n\nWe fit two additional models: `fit2` and `fit0`. `fit2` includes `sex` variable in addition to all variables included in `fit1` and could be better or worse than `fit1` as impact of sex is not big in the data set. `fit0` is intercept-only model and thus is very likely to be worse than `fit1` or `fit2`.\n\n### Model 2: Include sex in addition to age and household size as covariates.\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- brm(contacts ~ 1 + age + hhsize + sex, \n           data = d, \n           family = negbinomial(),\n           prior = my_priors,\n           iter = 1e4, cores = 4)\nsaveRDS(fit2, \"fit2.rds\")\n\nfit0 <- brm(contacts ~ 1, \n           data = d, \n           family = negbinomial(),\n           prior = set_prior(\"normal(0,5)\", class=\"Intercept\"),\n           iter = 1e4, cores = 4)\nsaveRDS(fit0, \"fit0.rds\")\n```\n:::\n\n\nSummary of fit0 and fit2\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- readRDS(\"fit2.rds\") \nfit0 <- readRDS(\"fit0.rds\")\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: contacts ~ 1 + age + hhsize + sex \n   Data: d (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.12      0.05     1.02     1.22 1.00    21089    14681\nage2          0.40      0.04     0.32     0.49 1.00    23623    15288\nage3         -0.47      0.05    -0.57    -0.37 1.00    23780    16196\nhhsize2       0.78      0.05     0.68     0.88 1.00    21501    16727\nhhsize3       1.10      0.05     1.01     1.20 1.00    20906    17372\nsex2          0.01      0.04    -0.06     0.08 1.00    30179    14675\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     5.28      0.45     4.49     6.22 1.00    30118    15669\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: contacts ~ 1 \n   Data: d (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.92      0.03     1.87     1.97 1.00    15994    12293\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     2.02      0.12     1.79     2.26 1.00    15828    12635\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nShape parameter estimates \n\n::: {.cell}\n\n```{.r .cell-code}\nprobs <- c(0.025, 0.25, 0.5, 0.75, 0.975)\nshp1 <- quantile(as.matrix(fit1)[,\"shape\"], probs=probs)\nshp2 <- quantile(as.matrix(fit2)[,\"shape\"], probs=probs)\nshp0 <- quantile(as.matrix(fit0)[,\"shape\"], probs=probs)\n\ndf <- data.frame(Model = \"Model 0\", t(shp0))\ndf <- rbind(df, data.frame(Model = \"Model 1\", t(shp1)),\n            data.frame(Model = \"Model 2\", t(shp2)))\n# df$percentile <- rep(as.character(100*probs),3)\n\nggplot(df, aes(x=Model))+\n  geom_linerange(aes(ymin=`X2.5.`, ymax=`X97.5.`))+\n  geom_linerange(aes(ymin=`X25.`, ymax=`X75.`), linewidth=1)+\n  geom_point(aes(x=Model, y=`X50.`))+\n  ggtitle(\"\")+\n  theme_light() + \n  labs(y=\"Inference for the shape parameter\", x=\"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nCompare fit0, fit1 and fit2 models\n\nUsing WAIC\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- add_criterion(fit1, \"waic\")\nfit0 <- add_criterion(fit0, \"waic\")\nfit2 <- add_criterion(fit2, \"waic\")\n\nwaic(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic  -2924.2 26.4\np_waic         2.1  0.2\nwaic        5848.4 52.9\n```\n:::\n\n```{.r .cell-code}\nwaic(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic  -2618.3 26.2\np_waic         5.9  0.3\nwaic        5236.6 52.5\n```\n:::\n\n```{.r .cell-code}\nwaic(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic  -2619.3 26.2\np_waic         6.9  0.4\nwaic        5238.5 52.4\n```\n:::\n\n```{.r .cell-code}\nloo_compare(fit1, fit2, fit0, criterion = \"waic\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     elpd_diff se_diff\nfit1    0.0       0.0 \nfit2   -1.0       0.3 \nfit0 -305.9      19.4 \n```\n:::\n:::\n\n\nUsing leave-one-out (LOO) cross-validation\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- add_criterion(fit1, \"loo\")\nfit0 <- add_criterion(fit0, \"loo\")\nfit2 <- add_criterion(fit2, \"loo\")\nloo_compare(fit1, fit2, fit0, criterion = \"loo\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     elpd_diff se_diff\nfit1    0.0       0.0 \nfit2   -1.0       0.3 \nfit0 -305.9      19.4 \n```\n:::\n:::\n\n\n`brms::loo_compare` uses the `loo::loo_compare` under the hood and and `loo::loo_compare` package produces the same results \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(loo)\nloo_fit0 <- loo(fit0)\nloo_fit1 <- loo(fit1)\nloo_fit2 <- loo(fit2)\n\nprint(loo_fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -2924.2 26.4\np_loo         2.1  0.2\nlooic      5848.4 52.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n:::\n\n```{.r .cell-code}\nprint(loo_fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -2618.3 26.2\np_loo         5.9  0.3\nlooic      5236.6 52.5\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n:::\n\n```{.r .cell-code}\nprint(loo_fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -2619.3 26.2\np_loo         6.9  0.4\nlooic      5238.5 52.4\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n:::\n\n```{.r .cell-code}\nbrms::loo_compare(loo_fit1, loo_fit2, loo_fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     elpd_diff se_diff\nfit1    0.0       0.0 \nfit2   -1.0       0.3 \nfit0 -305.9      19.4 \n```\n:::\n:::\n\n\nIt appears that `fit1` is the most favored by the looic and waic metrics. This implies that adding `sex` variable does not improve the model performance much while increasing the degree of freedom. This may be due to that the influence of `sex` is relatively small compared to the `age` and `household size`.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}