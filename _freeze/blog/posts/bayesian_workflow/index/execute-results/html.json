{
  "hash": "e591c3a7207cb4d7887291030c46d128",
  "result": {
    "markdown": "---\ntitle: \"Bayesian workflow: fake social contact data example\"\nauthor: \"Jong-Hoon Kim\"\ndate: \"2024-07-21\"\ncategories: [Bayesian workflow, negative binomial, social contact]\nimage: \"sample_figure.png\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Bayesian workflow\n\n\nThis post is an example analysis following a Bayesian workflow and uses simple models and fake data. I consulted a pre-print, [Bayesian Workflow](https://arxiv.org/abs/2011.01808) by Gelman _et al_. and [blog post](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#31_Example_Workflow_Executions) by Betancourt. \n \n[Gelman _et al_.](https://arxiv.org/abs/2011.01808) writes:\n\n  \"... Bayesian inference is just the formulation and computation of conditional probability or probability densities, $p(\\theta|y) \\propto p(\\theta) p(y|\\theta)$. Bayesian workflow includes the three steps of model building,\ninference, and model checking/improvement, along with the comparison of different models, not just for the purpose of model choice or model averaging but more importantly to better understand these models ... \"  \n\nLet's suppose, hoping to develop a way to better disease control strategies, we set out to measure the number of close contacts that a typical person makes in a day and variation of the close contacts across age and household size. \n\n\n### Conceptual analysis\n\nThe study is to examine the variations of the number of contacts a typical Korean makes in a day, specifically, variations by age and household size. [A prior study](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0050074) and other numerous studies showed that contact frequencies differ by age. And a significant fraction of contacts occur with household members and as such the contact frequencies will likely vary by household size. \n\nThere are three conceptual modelling approaches: descriptive, predictive and explanatory acording to [the study by Shmueli](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf), This study is best described as a descriptive study and the descriptive study does not directly aim at obtaining optimal predictive performance, but at capturing the data structure parsimoniously. For a descriptive model, interpretability, transportability and general usability are important criteria as described in the [article](ttps://diagnprognres.biomedcentral.com/articles/10.1186/s41512-020-00074-3). \n\n\nThe integer number of people that each person met during one day. Participants are classified by age and household size. The number of contacts are best captured with negative binomial distribution and mean umber of contacts is a function of age and household size.\n\n$$\ny_i \\sim \\text{NB}(y_i|\\mu_i,\\phi)=\\frac{\\Gamma (y_i + \\theta)}{\\Gamma (\\theta) y_i !}) \\left(\\frac{\\mu_i}{\\mu_i+\\phi} \\right)^y \\left(\\frac{\\phi}{\\mu_i+\\phi} \\right)^\\phi\n$${#eq-nb}\n\n$$\\text{log}(\\mu_i)= \\alpha + \\beta_{\\text{age}_i} +\\beta_{\\text{hhsize}_i}$${#eq-mu}\n\nWe take the fake-data simulation approach, which can help us understand our\ndata model and priors, what can be learned from an experiment, and the validity of the applied inference methods. \n\n### Generate the fake data\n\nParameters of interest are the ratios of contacts per day (i.e., rate ratios or relative risks) by age and household size. Plugging @eq-mu into @eq-nb becomes our generative model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameter values to be estimated\nintercept_true <- 3 # base number of contacts\nrr_age_true <- c(1.5,0.6) # relative number of contacts by age (age0 = 1)\nrr_hhsize_true <- c(2,2.6) # relative number of contacts by household size  (hhsize0 =1)  \nrr_sex_true <- c(1.2) # males have more frequent contacts, which is not modeled in model 1\nsize_true <- 5 # shape parameter for the negative binomial distribution\n\nset.seed(42)\n# 9 categories with >100 observations on average\nd <- data.frame(age = sample(1:3, 1000, replace=T),\n                hhsize = sample(1:3, 1000, replace=T), \n                sex = sample(1:2, 1000, replace=T))\nd$b_age <- \n  ifelse(d$age == 1, 1, \n         ifelse(d$age == 2, rr_age_true[1], rr_age_true[2])) # relative risk by age\nd$b_hhsize <- \n  ifelse(d$hhsize == 1, 1, \n         ifelse(d$hhsize == 2, rr_hhsize_true[1], rr_hhsize_true[2])) # relative risk by household size\n\nd$b_sex <- \n  ifelse(d$hhsize == 1, 1, rr_sex_true) # relative risk by\n\n# mean as a function of age and hhsize\na <- intercept_true \nlog_mu <- log(a) + log(d$b_age) + log(d$b_hhsize) + log(d$b_sex)\nd$mu <- exp(log_mu)\nd$age <- as.factor(d$age)\nd$hhsize <- as.factor(d$hhsize)\nd$sex <- as.factor(d$sex)\nd$contacts <- rnbinom(nrow(d), mu=d$mu, size=size_true) # size, aka, shape, dispersion\n```\n:::\n\n\nHistogram, mean, and variance of the data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nd |> \n  ggplot(aes(x=contacts))+\n  geom_histogram(binwidth=1, fill=\"steelblue\")+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmean(d$contacts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.85\n```\n:::\n\n```{.r .cell-code}\nvar(d$contacts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31.42492\n```\n:::\n:::\n\n\n\n## Building the model\n\n### Bayesian modeling using the `brms` package.\n\nWe first try the model that includes age and household size\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\n```\n:::\n\n\n### Prior predictive model using the `sample_prior = \"only\"` argument\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prior distribution\na_mean <- 0\na_scale <- 1.5 # chosen with an assumption that exp(2*a_scale) will likely cover plausible values \nb_mean <- 0\nb_scale <- 1.5\n\nshp_alpha <- 0.8 # 0.4 (brms default) causes divergent transitions,\nshp_beta <- 0.3\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_priors <- \n  c(prior_string(paste0(\"normal(\", a_mean, \",\", a_scale,\")\"), \n                 class = \"Intercept\"),\n    prior_string(paste0(\"normal(\", b_mean, \",\", b_scale,\")\"),\n                 class = \"b\"),\n    prior_string(paste0(\"inv_gamma(\", shp_alpha, \",\", shp_beta,\")\"), \n                 class=\"shape\"))\n\nprior_pred <- brm(contacts ~ 1 + age + hhsize,\n                 data = d,\n                 family = negbinomial(),\n                 prior = my_priors,\n                 iter = 1e4, sample_prior = \"only\", cores = 4)\n\nsaveRDS(prior_pred, \"prior_pred.rds\")\n```\n:::\n\n\n\n### Prior predictive checks\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred <- readRDS(\"prior_pred.rds\")\npriorpc <- pp_check(prior_pred, type=\"bars\", ndraws = 200)\n\npriorpc$data |> \n  ggplot(aes(x=x))+\n  geom_col(aes(y=y_obs, fill=\"Data\"))+\n  geom_point(aes(y=m, color=\"Prior\"))+\n  geom_linerange(aes(ymax=h, ymin=l, color=\"Prior\"))+\n  scale_x_continuous(limits=c(-1,30))+\n  labs(x=\"number of contacts\", y= \"frequency\")+\n  scale_color_manual(\"\", values=c(\"Prior\"=\"darkgreen\"))+\n  scale_fill_manual(\"\", values=c(\"Data\"=\"steelblue\"))+\n  theme_bw()+\n  theme(legend.position=c(0.8,0.8))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n## Fit the model\n\n[Gelman _et al_.](https://arxiv.org/abs/2011.01808)\nwrites: \n\" ... The first step in validating computation is to check that the model actually finishes the fitting process in an acceptable time frame and the convergence diagnostics are reasonable. In the context of HMC, this is primarily the absence of divergent transitions, Rb diagnostic near 1, and sufficient\neffective sample sizes for the central tendency, the tail quantiles, and the energy (Vehtari et al., 2020). ...\" \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- brm(contacts ~ 1 + age + hhsize, \n           data = d, \n           family = negbinomial(),\n           prior = my_priors,\n           iter = 1e4, cores = 4)\nsaveRDS(fit1, \"fit1.rds\")\n```\n:::\n\n\n`brms` package reports all the relevant information.\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- readRDS(\"fit1.rds\")\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: contacts ~ 1 + age + hhsize \n   Data: d (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.13      0.05     1.04     1.22 1.00    17035    13697\nage2          0.40      0.04     0.32     0.49 1.00    20548    15508\nage3         -0.47      0.05    -0.57    -0.37 1.00    20229    15028\nhhsize2       0.78      0.05     0.68     0.88 1.00    17675    15906\nhhsize3       1.10      0.05     1.01     1.20 1.00    17685    16213\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     5.30      0.45     4.48     6.24 1.00    22342    14546\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n### Plot posterior predictive values along with prior predictive values\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred <- readRDS(\"prior_pred.rds\")\npriorpc <- pp_check(prior_pred, type=\"bars\", ndraws = 200)\npostpc <- pp_check(fit1, type=\"bars\", ndraws = 200)\n\npostpc$data |> \n  ggplot(aes(x=x))+\n  geom_col(aes(y=y_obs, fill=\"Data\"))+\n  geom_point(data=priorpc$data, aes(y=m, color=\"Prior\"))+\n  geom_linerange(data=priorpc$data,aes(ymax=h, ymin=l, color=\"Prior\"))+\n  geom_point(aes(y=m, color=\"Posterior\"))+\n  geom_linerange(aes(ymax=h, ymin=l, color=\"Posterior\"))+\n  scale_x_continuous(limits=c(-1,30))+\n  labs(x=\"number of contacts\", y= \"frequency\")+\n  scale_color_manual(\"\", values=c(\"Prior\"=\"darkgreen\",\n                               \"Posterior\"=\"firebrick\"))+\n  scale_fill_manual(\"\", values=c(\"Data\"=\"steelblue\"))+\n  theme_bw()+\n  theme(legend.position=c(0.8,0.8))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n## Prior and posterior distributions of parameters\n\nTrace plots and histograms\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1, pars = \"^b_\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# plot(fit, pars = \".*age*.\")\n# plot(fit, pars = \".*hhsize*.\")\n```\n:::\n\n\nCorrelations\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit1, pars = \".*age*.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n$\\beta_{\\text{age}}$ parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_post <- as.data.frame(fit1)\nx <- seq(-2, 2, 0.01)\ndf <- data.frame(x=seq(-2, 2, 0.01))\ndf$prior_density <-  dnorm(df$x, b_mean, b_scale)\n\nplot(exp(x), dnorm(x, b_mean, b_scale), type=\"l\", ylim=c(0, 20), \n     xlab=\"value\", ylab=\"density\", main=expression(beta[age]))\nlines(density(exp(df_post$b_age2)), col=2)\nlines(density(exp(df_post$b_age3)), col=3)\nabline(v=rr_age_true, col=\"purple\", lwd=2)\n\nlegend(\"topright\",\n       bty = \"n\",\n       lty=1,\n       col=c(1,2,3,\"purple\"),\n       legend=c(\"Prior\", \"age2\", \"age3\",\"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ggplot2 way\n# ggplot()+\n#   geom_line(data=df, aes(x=exp(x), y=prior_density, color=\"Prior\"))+\n#   geom_density(data=df_post, aes(x=exp(b_age2), color=\"Posterior b_age2\"))+\n#   geom_density(data=df_post, aes(x=exp(b_age3), color=\"Posterior b_age3\"))+\n#   scale_color_manual(values=c(\"Prior\"=\"forestgreen\", \n#                               \"Posterior b_age2\"=\"firebrick\",\n#                               \"Posterior b_age3\"=\"steelblue\"))+\n#   labs(color=\"\", x=\"value\", y=\"density\")+\n#   theme(legend.position=\"bottom\")\n```\n:::\n\n\n$\\beta_{\\text{hhsize}}$ parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(exp(x), dnorm(x, b_mean, b_scale), type=\"l\", ylim=c(0,5), \n     xlab=\"value\", ylab=\"density\", main=expression(beta[hhsize]))\nlines(density(exp(df_post$b_hhsize2)), col=2)\nlines(density(exp(df_post$b_hhsize3)), col=3)\nabline(v=rr_hhsize_true, col=\"purple\", lwd=2)\n\nlegend(\"topright\",\n       bty = \"n\",\n       lty=1,\n       col=c(1,2,3,\"purple\"),\n       legend=c(\"Prior\", \"hhsize2\", \"hhsize3\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nIntercept\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(-3, 3,0.01)\nplot(exp(x), dnorm(x, a_mean, a_scale), type=\"l\", ylim=c(0,4), \n     xlab=\"value\", ylab=\"density\", main=\"Intercept\")\nlines(density(exp(df_post$b_Intercept)), col=2)\nabline(v=intercept_true, col=\"purple\", lwd=2)\nlegend(\"topright\",\n       bty = \"n\",\n       lty=1,\n       col=c(1,2,\"purple\"),\n       legend=c(\"Prior\", \"Posterior\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nShape parameter\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(extraDistr)\n\nx <- seq(0,10,0.01)\nplot(x, dinvgamma(x, shp_alpha, shp_beta), type=\"l\", \n     ylim=c(0,2), xlab=\"value\", ylab=\"density\", main=\"Shape\")\nlines(density(df_post$shape), col=2)\nabline(v=size_true, col=\"purple\", lwd=2)\nlegend(\"topright\",\n       bty = \"n\",\n       lty=1,\n       col=c(1,2,\"purple\"),\n       legend=c(\"Prior\", \"Posterior\", \"True\"),\n       inset=0.02)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n## Model evaluation\n\nLeave-one-out (LOO) cross validation as suggested in [Vehtari *et al.*](https://link.springer.com/article/10.1007/s11222-016-9696-4) and  [Gelman *et al.*](https://link.springer.com/article/10.1007/s11222-013-9416-2).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- brm(contacts ~ 1 + age + hhsize + sex, \n           data = d, \n           family = negbinomial(),\n           prior = my_priors,\n           iter = 1e4, cores = 4)\nsaveRDS(fit2, \"fit2.rds\")\n```\n:::\n\n\nSummary of fit2\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- readRDS(\"fit2.rds\")\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: contacts ~ 1 + age + hhsize + sex \n   Data: d (Number of observations: 1000) \n  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.12      0.05     1.02     1.22 1.00    21089    14681\nage2          0.40      0.04     0.32     0.49 1.00    23623    15288\nage3         -0.47      0.05    -0.57    -0.37 1.00    23780    16196\nhhsize2       0.78      0.05     0.68     0.88 1.00    21501    16727\nhhsize3       1.10      0.05     1.01     1.20 1.00    20906    17372\nsex2          0.01      0.04    -0.06     0.08 1.00    30179    14675\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     5.28      0.45     4.49     6.22 1.00    30118    15669\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nCompare fit1 and fit2 suing leave-one out (LOO) crossvalidation\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(loo)\nloo_fit1 <- loo(fit1)\nloo_fit2 <- loo(fit2)\nsaveRDS(loo_fit1, \"loo_fit1.rds\")\nsaveRDS(loo_fit2, \"loo_fit2.rds\")\n\nprint(loo_fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -2618.3 26.2\np_loo         5.9  0.3\nlooic      5236.6 52.5\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n:::\n\n```{.r .cell-code}\nprint(loo_fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nComputed from 20000 by 1000 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo  -2619.3 26.2\np_loo         6.9  0.4\nlooic      5238.5 52.4\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n:::\n\n```{.r .cell-code}\nloo_compare(loo_fit1, loo_fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     elpd_diff se_diff\nfit1  0.0       0.0   \nfit2 -1.0       0.3   \n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}