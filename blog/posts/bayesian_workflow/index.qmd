---
title: "Bayesian workflow: fake social contact data example [in progress]"
author: "Jong-Hoon Kim"
date: "2024-07-21"
categories: [Bayesian workflow, negative binomial, social contact]
image: "sample_figure.png"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```

## Bayesian workflow


This post is an example analysis following a Bayesian workflow and uses simple models and fake data. I consulted a pre-print, [Bayesian Workflow](https://arxiv.org/abs/2011.01808) by Gelman _et al_. and [blog post](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#31_Example_Workflow_Executions) by Betancourt. 
 
[Gelman _et al_.](https://arxiv.org/abs/2011.01808) writes:

  "... Bayesian inference is just the formulation and computation of conditional probability or probability densities, $p(\theta|y) \propto p(\theta) p(y|\theta)$. Bayesian workflow includes the three steps of model building,
inference, and model checking/improvement, along with the comparison of different models, not just for the purpose of model choice or model averaging but more importantly to better understand these models ... "  

Let's suppose, hoping to develop a way to better disease control strategies, we set out to measure the number of close contacts that a typical person makes in a day and variation of the close contacts across age and household size. 


### Conceptual analysis

The study is to examine the variations of the number of contacts a typical Korean makes in a day, specifically, variations by age and household size. [A prior study](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0050074) and other numerous studies showed that contact frequencies differ by age. And a significant fraction of contacts occur with household members and as such the contact frequencies will likely vary by household size. 

There are three conceptual modelling approaches: descriptive, predictive and explanatory acording to [the study by Shmueli](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf), This study is best described as a descriptive study and the descriptive study does not directly aim at obtaining optimal predictive performance, but at capturing the data structure parsimoniously. For a descriptive model, interpretability, transportability and general usability are important criteria as described in the [article](ttps://diagnprognres.biomedcentral.com/articles/10.1186/s41512-020-00074-3). 


The integer number of people that each person met during one day. Participants are classified by age and household size. The number of contacts are best captured with negative binomial distribution and mean umber of contacts is a function of age and household size.

$$
y_i \sim \text{NB}(y_i|\mu_i,\phi)=\frac{\Gamma (y_i + \theta)}{\Gamma (\theta) y_i !}) \left(\frac{\mu_i}{\mu_i+\phi} \right)^y \left(\frac{\phi}{\mu_i+\phi} \right)^\phi
$${#eq-nb}

$$\text{log}(\mu_i)= \alpha + \beta_{\text{age}_i} +\beta_{\text{hhsize}_i}$${#eq-mu}

We take the fake-data simulation approach, which can help us understand our
data model and priors, what can be learned from an experiment, and the validity of the applied inference methods. 

### Generate the fake data

Parameters of interest are the ratios of contacts per day (i.e., rate ratios or relative risks) by age and household size. Plugging @eq-mu into @eq-nb becomes our generative model.

```{r}
# parameter values to be estimated
intercept_true <- 3 # base number of contacts
rr_age_true <- c(1.5,0.6) # relative number of contacts by age (age0 = 1)
rr_hhsize_true <- c(2,2.6) # relative number of contacts by household size  (hhsize0 =1)  
rr_sex_true <- c(1.2) # males have more frequent contacts, which is not modeled in model 1
size_true <- 5 # shape parameter for the negative binomial distribution

set.seed(42)
# 9 categories with >100 observations on average
d <- data.frame(age = sample(1:3, 1000, replace=T),
                hhsize = sample(1:3, 1000, replace=T), 
                sex = sample(1:2, 1000, replace=T))
d$b_age <- 
  ifelse(d$age == 1, 1, 
         ifelse(d$age == 2, rr_age_true[1], rr_age_true[2])) # relative risk by age
d$b_hhsize <- 
  ifelse(d$hhsize == 1, 1, 
         ifelse(d$hhsize == 2, rr_hhsize_true[1], rr_hhsize_true[2])) # relative risk by household size

d$b_sex <- 
  ifelse(d$hhsize == 1, 1, rr_sex_true) # relative risk by

# mean as a function of age and hhsize
a <- intercept_true 
log_mu <- log(a) + log(d$b_age) + log(d$b_hhsize) + log(d$b_sex)
d$mu <- exp(log_mu)
d$age <- as.factor(d$age)
d$hhsize <- as.factor(d$hhsize)
d$sex <- as.factor(d$sex)
d$contacts <- rnbinom(nrow(d), mu=d$mu, size=size_true) # size, aka, shape, dispersion
```

Histogram, mean, and variance of the data
```{r}
library(tidyverse)
d |> 
  ggplot(aes(x=contacts))+
  geom_histogram(binwidth=1, fill="steelblue")+
  theme_light()

mean(d$contacts)
var(d$contacts)
```


## Building the model

### Bayesian modeling using the `brms` package.

We first try the model that includes age and household size
```{r}
library(brms)
```

### Prior predictive model using the `sample_prior = "only"` argument

```{r}
# prior distribution
a_mean <- 0
a_scale <- 1.5 # chosen with an assumption that exp(2*a_scale) will likely cover plausible values 
b_mean <- 0
b_scale <- 1.5

shp_alpha <- 0.8 # 0.4 (brms default) causes divergent transitions,
shp_beta <- 0.3
```

```{r, eval=FALSE}
my_priors <- 
  c(prior_string(paste0("normal(", a_mean, ",", a_scale,")"), 
                 class = "Intercept"),
    prior_string(paste0("normal(", b_mean, ",", b_scale,")"),
                 class = "b"),
    prior_string(paste0("inv_gamma(", shp_alpha, ",", shp_beta,")"), 
                 class="shape"))

prior_pred <- brm(contacts ~ 1 + age + hhsize,
                 data = d,
                 family = negbinomial(),
                 prior = my_priors,
                 iter = 1e4, sample_prior = "only", cores = 4)

saveRDS(prior_pred, "prior_pred.rds")
```


### Prior predictive checks
```{r}
prior_pred <- readRDS("prior_pred.rds")
priorpc <- pp_check(prior_pred, type="bars", ndraws = 200)

priorpc$data |> 
  ggplot(aes(x=x))+
  geom_col(aes(y=y_obs, fill="Data"))+
  geom_point(aes(y=m, color="Prior"))+
  geom_linerange(aes(ymax=h, ymin=l, color="Prior"))+
  scale_x_continuous(limits=c(-1,30))+
  labs(x="number of contacts", y= "frequency")+
  scale_color_manual("", values=c("Prior"="darkgreen"))+
  scale_fill_manual("", values=c("Data"="steelblue"))+
  theme_bw()+
  theme(legend.position=c(0.8,0.8))
```


## Fit the model

[Gelman _et al_.](https://arxiv.org/abs/2011.01808)
writes: 
" ... The first step in validating computation is to check that the model actually finishes the fitting process in an acceptable time frame and the convergence diagnostics are reasonable. In the context of HMC, this is primarily the absence of divergent transitions, Rb diagnostic near 1, and sufficient
effective sample sizes for the central tendency, the tail quantiles, and the energy (Vehtari et al., 2020). ..." 

```{r, eval=FALSE}
fit1 <- brm(contacts ~ 1 + age + hhsize, 
           data = d, 
           family = negbinomial(),
           prior = my_priors,
           iter = 1e4, cores = 4)
saveRDS(fit1, "fit1.rds")
```

`brms` package reports all the relevant information.
```{r}
fit1 <- readRDS("fit1.rds")
summary(fit1)
```

### Plot posterior predictive values along with prior predictive values
```{r}
prior_pred <- readRDS("prior_pred.rds")
priorpc <- pp_check(prior_pred, type="bars", ndraws = 200)
postpc <- pp_check(fit1, type="bars", ndraws = 200)

postpc$data |> 
  ggplot(aes(x=x))+
  geom_col(aes(y=y_obs, fill="Data"))+
  geom_point(data=priorpc$data, aes(y=m, color="Prior"))+
  geom_linerange(data=priorpc$data,aes(ymax=h, ymin=l, color="Prior"))+
  geom_point(aes(y=m, color="Posterior"))+
  geom_linerange(aes(ymax=h, ymin=l, color="Posterior"))+
  scale_x_continuous(limits=c(-1,30))+
  labs(x="number of contacts", y= "frequency")+
  scale_color_manual("", values=c("Prior"="darkgreen",
                               "Posterior"="firebrick"))+
  scale_fill_manual("", values=c("Data"="steelblue"))+
  theme_bw()+
  theme(legend.position=c(0.8,0.8))
```


## Prior and posterior distributions of parameters

Trace plots and histograms
```{r}
plot(fit1, pars = "^b_")
# plot(fit, pars = ".*age*.")
# plot(fit, pars = ".*hhsize*.")
```

Correlations
```{r}
pairs(fit1, pars = ".*age*.")
```


$\beta_{\text{age}}$ parameter

```{r}
df_post <- as.data.frame(fit1)
x <- seq(-2, 2, 0.01)
df <- data.frame(x=seq(-2, 2, 0.01))
df$prior_density <-  dnorm(df$x, b_mean, b_scale)

plot(exp(x), dnorm(x, b_mean, b_scale), type="l", ylim=c(0, 20), 
     xlab="value", ylab="density", main=expression(beta[age]))
lines(density(exp(df_post$b_age2)), col=2)
lines(density(exp(df_post$b_age3)), col=3)
abline(v=rr_age_true, col="purple", lwd=2)

legend("topright",
       bty = "n",
       lty=1,
       col=c(1,2,3,"purple"),
       legend=c("Prior", "age2", "age3","True"),
       inset=0.02)

# ggplot2 way
# ggplot()+
#   geom_line(data=df, aes(x=exp(x), y=prior_density, color="Prior"))+
#   geom_density(data=df_post, aes(x=exp(b_age2), color="Posterior b_age2"))+
#   geom_density(data=df_post, aes(x=exp(b_age3), color="Posterior b_age3"))+
#   scale_color_manual(values=c("Prior"="forestgreen", 
#                               "Posterior b_age2"="firebrick",
#                               "Posterior b_age3"="steelblue"))+
#   labs(color="", x="value", y="density")+
#   theme(legend.position="bottom")
```

$\beta_{\text{hhsize}}$ parameter

```{r}
plot(exp(x), dnorm(x, b_mean, b_scale), type="l", ylim=c(0,5), 
     xlab="value", ylab="density", main=expression(beta[hhsize]))
lines(density(exp(df_post$b_hhsize2)), col=2)
lines(density(exp(df_post$b_hhsize3)), col=3)
abline(v=rr_hhsize_true, col="purple", lwd=2)

legend("topright",
       bty = "n",
       lty=1,
       col=c(1,2,3,"purple"),
       legend=c("Prior", "hhsize2", "hhsize3", "True"),
       inset=0.02)
```


Intercept
```{r}
x <- seq(-3, 3,0.01)
plot(exp(x), dnorm(x, a_mean, a_scale), type="l", ylim=c(0,4), 
     xlab="value", ylab="density", main="Intercept")
lines(density(exp(df_post$b_Intercept)), col=2)
abline(v=intercept_true, col="purple", lwd=2)
legend("topright",
       bty = "n",
       lty=1,
       col=c(1,2,"purple"),
       legend=c("Prior", "Posterior", "True"),
       inset=0.02)
```

Shape parameter
```{r}
library(extraDistr)

x <- seq(0,10,0.01)
plot(x, dinvgamma(x, shp_alpha, shp_beta), type="l", 
     ylim=c(0,2), xlab="value", ylab="density", main="Shape")
lines(density(df_post$shape), col=2)
abline(v=size_true, col="purple", lwd=2)
legend("topright",
       bty = "n",
       lty=1,
       col=c(1,2,"purple"),
       legend=c("Prior", "Posterior", "True"),
       inset=0.02)
```


## Model evaluation

Leave-one-out (LOO) cross validation as suggested in [Vehtari *et al.*](https://link.springer.com/article/10.1007/s11222-016-9696-4) and  [Gelman *et al.*](https://link.springer.com/article/10.1007/s11222-013-9416-2).

We fit two additional models: `fit2` and `fit0`. `fit2` includes `sex` variable in addition to all variables included in `fit1` and could be better or worse than `fit1` as impact of sex is not big in the data set. `fit0` is intercept-only model and thus is very likely to be worse than `fit1` or `fit2`.
```{r, eval=FALSE}
fit2 <- brm(contacts ~ 1 + age + hhsize + sex, 
           data = d, 
           family = negbinomial(),
           prior = my_priors,
           iter = 1e4, cores = 4)
saveRDS(fit2, "fit2.rds")

fit0 <- brm(contacts ~ 1, 
           data = d, 
           family = negbinomial(),
           prior = set_prior("normal(0,5)", class="Intercept"),
           iter = 1e4, cores = 4)
saveRDS(fit0, "fit0.rds")
```


Summary of fit2 and fit2
```{r}
fit2 <- readRDS("fit2.rds") 
fit0 <- readRDS("fit0.rds")
summary(fit2)
summary(fit0)
```

Shape parameter estimates 
```{r}
probs <- c(0.025, 0.25, 0.5, 0.75, 0.975)
shp1 <- quantile(as.matrix(fit1)[,"shape"], probs=probs)
shp2 <- quantile(as.matrix(fit2)[,"shape"], probs=probs)
shp0 <- quantile(as.matrix(fit0)[,"shape"], probs=probs)

df <- data.frame(Model = "Model0", t(shp0))
df <- rbind(df, data.frame(Model = "Model1", t(shp1)),
            data.frame(Model = "Model2", t(shp2)))
# df$percentile <- rep(as.character(100*probs),3)

ggplot(df, aes(x=Model))+
  geom_linerange(aes(ymin=`X2.5.`, ymax=`X97.5.`))+
  geom_linerange(aes(ymin=`X25.`, ymax=`X75.`), linewidth=1)+
  geom_point(aes(x=Model, y=`X50.`))+
  ggtitle("")+
  theme_light() + 
  labs(y="inference for the shape parameter", x="")
```

Compare fit1 and fit2 suing leave-one out (LOO) cross-validation
```{r, eval=FALSE}
library(loo)
loo_fit1 <- loo(fit1)
loo_fit2 <- loo(fit2)
loo_fit0 <- loo(fit0)
saveRDS(loo_fit1, "loo_fit1.rds")
saveRDS(loo_fit2, "loo_fit2.rds")
saveRDS(loo_fit0, "loo_fit0.rds")
```

```{r}
loo_fit1 <- readRDS("loo_fit1.rds")
loo_fit2 <- readRDS("loo_fit2.rds")
loo_fit0 <- readRDS("loo_fit0.rds")
print(loo_fit1)
print(loo_fit2)
print(loo_fit0)
loo_compare(loo_fit1, loo_fit2, loo_fit0)
```

